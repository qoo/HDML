{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Aug 12 17:34:25 2019\n",
    "\n",
    "@author: Cheng-Hung\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import h5py\n",
    "import fuel\n",
    "from fuel.datasets.hdf5 import H5PYDataset\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def preprocess(hwc_bgr_image, size):\n",
    "    hwc_rgb_image = cv2.cvtColor(hwc_bgr_image, cv2.COLOR_BGR2RGB)\n",
    "    resized = cv2.resize(hwc_rgb_image, (size))\n",
    "    chw_image = np.transpose(resized, axes=(2, 0, 1))\n",
    "    return chw_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    dataset_name = \"cars196\"\n",
    "    archive_basename = \"car_ims\"\n",
    "\n",
    "    fuel_root_path = \"./data\"\n",
    "#     fuel_root_path = \"./datasets/data\"\n",
    "    fuel_data_path = os.path.join(fuel_root_path, dataset_name)\n",
    "    image_filepath = os.path.join(fuel_data_path, archive_basename + \".tar.gz\")\n",
    "    label_filepath = os.path.join(fuel_data_path, \"cars_annos.mat\")\n",
    "\n",
    "    # Extract car_ims.tgz if car_ims directory does not exist\n",
    "    with tarfile.open(image_filepath, \"r\") as tf:\n",
    "        jpg_filenames = [fn for fn in tf.getnames() if fn.endswith(\".jpg\")]\n",
    "    jpg_filenames.sort()\n",
    "    num_examples = len(jpg_filenames)  # ????\n",
    "    if not os.path.exists(os.path.join(fuel_data_path, archive_basename)):\n",
    "        subprocess.call([\"tar\", \"zxvf\", image_filepath.replace(\"\\\\\", \"/\"),\n",
    "                         \"-C\", fuel_data_path.replace(\"\\\\\", \"/\"),\n",
    "                         \"--force-local\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car_ims/000001.jpg', 'car_ims/000002.jpg', 'car_ims/000003.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpg_filenames[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Extract class labels\n",
    "    cars_annos = loadmat(label_filepath)\n",
    "    annotations = cars_annos[\"annotations\"].ravel()\n",
    "    annotations = sorted(annotations, key=lambda a: str(a[0][0]))\n",
    "    class_labels = []\n",
    "    for annotation in annotations:\n",
    "        class_label = int(annotation[5])\n",
    "        class_labels.append(class_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(class_labels[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([u'car_ims/000001.jpg'], dtype='<U18'), array([[112]], dtype=uint8), array([[7]], dtype=uint8), array([[853]], dtype=uint16), array([[717]], dtype=uint16), array([[1]], dtype=uint8), array([[0]], dtype=uint8)),\n",
       " (array([u'car_ims/000002.jpg'], dtype='<U18'), array([[48]], dtype=uint8), array([[24]], dtype=uint8), array([[441]], dtype=uint16), array([[202]], dtype=uint8), array([[1]], dtype=uint8), array([[0]], dtype=uint8)),\n",
       " (array([u'car_ims/000003.jpg'], dtype='<U18'), array([[7]], dtype=uint8), array([[4]], dtype=uint8), array([[277]], dtype=uint16), array([[180]], dtype=uint8), array([[1]], dtype=uint8), array([[0]], dtype=uint8))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # open hdf5 file\n",
    "    hdf5_filename = \"cars196.hdf5\"\n",
    "    hdf5_filepath = os.path.join(fuel_data_path, hdf5_filename)\n",
    "    hdf5 = h5py.File(hdf5_filepath, mode=\"w\")\n",
    "\n",
    "    # store images\n",
    "    image_size = (256, 256)\n",
    "    array_shape = (num_examples, 3) + image_size\n",
    "    ds_images = hdf5.create_dataset(\"images\", array_shape, dtype=np.uint8)\n",
    "    ds_images.dims[0].label = \"batch\"\n",
    "    ds_images.dims[1].label = \"channel\"\n",
    "    ds_images.dims[2].label = \"height\"\n",
    "    ds_images.dims[3].label = \"width\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./data/cars196/cars196.hdf5: 100%|██████████| 16185/16185 [02:51<00:00, 94.14it/s] \n"
     ]
    }
   ],
   "source": [
    "    # write images to the disk\n",
    "    for i, filename in tqdm(enumerate(jpg_filenames), total=num_examples,\n",
    "                            desc=hdf5_filepath):\n",
    "        raw_image = cv2.imread(os.path.join(fuel_data_path, filename),\n",
    "                               cv2.IMREAD_COLOR)  # BGR image\n",
    "        image = preprocess(raw_image, image_size)\n",
    "        ds_images[i] = image\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # store the targets (class labels)\n",
    "    targets = np.array(class_labels, np.int32).reshape(num_examples, 1)\n",
    "    ds_targets = hdf5.create_dataset(\"targets\", data=targets)\n",
    "    ds_targets.dims[0].label = \"batch\"\n",
    "    ds_targets.dims[1].label = \"class_labels\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # specify the splits (labels 1~98 for train, 99~196 for test)\n",
    "    test_head = class_labels.index(99)\n",
    "    split_train, split_test = (0, test_head), (test_head, num_examples)\n",
    "    split_dict = dict(train=dict(images=split_train, targets=split_train),\n",
    "                      test=dict(images=split_test, targets=split_test))\n",
    "    hdf5.attrs[\"split\"] = H5PYDataset.create_split_array(split_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 8054)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': {'images': (8054, 16185), 'targets': (8054, 16185)},\n",
       " 'train': {'images': (0, 8054), 'targets': (0, 8054)}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'images', u'targets']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(hdf5.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('test', 'images', 8054, 16185, <HDF5 object reference (null)>,  True, '.'),\n",
       "       ('test', 'targets', 8054, 16185, <HDF5 object reference (null)>,  True, '.'),\n",
       "       ('train', 'images',    0,  8054, <HDF5 object reference (null)>,  True, '.'),\n",
       "       ('train', 'targets',    0,  8054, <HDF5 object reference (null)>,  True, '.')],\n",
       "      dtype=[('split', 'S5'), ('source', 'S7'), ('start', '<i8'), ('stop', '<i8'), ('indices', 'O'), ('available', '?'), ('comment', 'S1')])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5.attrs['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     hdf5.flush()\n",
    "#     hdf5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2]], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[88:92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
